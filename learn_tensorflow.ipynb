{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "#基本语法\n",
    "import tensorflow as tf\n",
    "a=tf.constant(3)\n",
    "b=tf.constant(4)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(a+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.4937813]]\n"
     ]
    }
   ],
   "source": [
    "#前向传播,输入数据固定\n",
    "x=tf.constant([[0.7,0.5]])\n",
    "w1=tf.Variable(tf.truncated_normal(shape=[2,3],stddev=1,seed=1))\n",
    "w2=tf.Variable(tf.truncated_normal(shape=[3,1],stddev=1,seed=1))\n",
    "\n",
    "a=tf.matmul(x,w1)\n",
    "y=tf.matmul(a,w2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.4937813]\n",
      " [1.438938 ]\n",
      " [2.0179148]]\n"
     ]
    }
   ],
   "source": [
    "#前向传播，投喂已知数据\n",
    "x=tf.placeholder(tf.float32,shape=[3,2])\n",
    "w1=tf.Variable(tf.truncated_normal(shape=[2,3],seed=1))\n",
    "w2=tf.Variable(tf.truncated_normal(shape=[3,1],seed=1))\n",
    "\n",
    "a=tf.matmul(x,w1)\n",
    "y=tf.matmul(a,w2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op=tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(y,feed_dict={x:[[0.7,0.5],[0.4,0.3],[0.5,0.6]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4815356 ]\n",
      " [0.95740247]\n",
      " [2.4937813 ]]\n",
      "W1:\n",
      " [[-0.8113182   1.4845988   0.06532937]\n",
      " [ 0.0992484   0.6396971   1.6108712 ]]\n",
      "W2:\n",
      " [[-0.8113182 ]\n",
      " [ 1.4845988 ]\n",
      " [ 0.06532937]]\n"
     ]
    }
   ],
   "source": [
    "#前向传播，投喂未知数据\n",
    "x=tf.placeholder(tf.float32,shape=[None,2])\n",
    "w1=tf.Variable(tf.truncated_normal(shape=[2,3],stddev=1,seed=1))\n",
    "w2=tf.Variable(tf.truncated_normal(shape=[3,1],stddev=1,seed=1))\n",
    "\n",
    "a=tf.matmul(x,w1)\n",
    "y=tf.matmul(a,w2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(y,feed_dict={x:[[0.1,0.2],[0.3,0.1],[0.7,0.5]]}))\n",
    "    print(\"W1:\\n\",sess.run(w1))\n",
    "    print(\"W2:\\n\",sess.run(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      " [[0.83494319 0.11482951]\n",
      " [0.66899751 0.46594987]\n",
      " [0.60181666 0.58838408]\n",
      " [0.31836656 0.20502072]\n",
      " [0.87043944 0.02679395]\n",
      " [0.41539811 0.43938369]\n",
      " [0.68635684 0.24833404]\n",
      " [0.97315228 0.68541849]\n",
      " [0.03081617 0.89479913]\n",
      " [0.24665715 0.28584862]\n",
      " [0.31375667 0.47718349]\n",
      " [0.56689254 0.77079148]\n",
      " [0.7321604  0.35828963]\n",
      " [0.15724842 0.94294584]\n",
      " [0.34933722 0.84634483]\n",
      " [0.50304053 0.81299619]\n",
      " [0.23869886 0.9895604 ]\n",
      " [0.4636501  0.32531094]\n",
      " [0.36510487 0.97365522]\n",
      " [0.73350238 0.83833013]\n",
      " [0.61810158 0.12580353]\n",
      " [0.59274817 0.18779828]\n",
      " [0.87150299 0.34679501]\n",
      " [0.25883219 0.50002932]\n",
      " [0.75690948 0.83429824]\n",
      " [0.29316649 0.05646578]\n",
      " [0.10409134 0.88235166]\n",
      " [0.06727785 0.57784761]\n",
      " [0.38492705 0.48384792]\n",
      " [0.69234428 0.19687348]\n",
      " [0.42783492 0.73416985]\n",
      " [0.09696069 0.04883936]]\n",
      "Y:\n",
      " [[1], [0], [0], [1], [1], [1], [1], [0], [1], [1], [1], [0], [0], [0], [0], [0], [0], [1], [0], [0], [1], [1], [0], [1], [0], [1], [1], [1], [1], [1], [0], [1]]\n",
      "before trian:\n",
      "W1:\n",
      " [[-0.8113182   1.4845988   0.06532937]\n",
      " [ 0.0992484   0.6396971   1.6108712 ]]\n",
      "W2:\n",
      " [[-0.8113182 ]\n",
      " [ 1.4845988 ]\n",
      " [ 0.06532937]]\n",
      "\n",
      "\n",
      "after 0 epochs,the loss is 1.81758 \n",
      "after 100 epochs,the loss is 0.386508 \n",
      "after 200 epochs,the loss is 0.383766 \n",
      "after 300 epochs,the loss is 0.383584 \n",
      "after 400 epochs,the loss is 0.383571 \n",
      "after 500 epochs,the loss is 0.383571 \n",
      "after 600 epochs,the loss is 0.383571 \n",
      "after 700 epochs,the loss is 0.383571 \n",
      "after 800 epochs,the loss is 0.383572 \n",
      "after 900 epochs,the loss is 0.383571 \n",
      "after train:\n",
      "W1:\n",
      " [[-0.39597678  0.80356     0.18755336]\n",
      " [ 0.17581318  0.49371946  1.5931308 ]]\n",
      "W2:\n",
      " [[-0.41719812]\n",
      " [ 0.6938029 ]\n",
      " [-0.103618  ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "BATCH_SIZE = 8\n",
    "seed = 23455\n",
    "\n",
    "#0.准备数据\n",
    "#基于seed产生随机数\n",
    "rng = np.random.RandomState(seed)\n",
    "#随机数返回32行2列的矩阵，表示32组体积和重量 作为输入数据集\n",
    "X=rng.rand(32,2)\n",
    "#假设评判标准为 体积和重量 和 超过1的话，对应的label为1，否则为0\n",
    "Y=[[int(x0+x1<1)] for (x0,x1) in X]\n",
    "print(\"X:\\n\",X)\n",
    "print(\"Y:\\n\",Y)\n",
    "\n",
    "#1.构造网络\n",
    "#投喂的数据\n",
    "x=tf.placeholder(tf.float32,shape=[None,2])\n",
    "y=tf.placeholder(tf.float32,shape=[None,1])\n",
    "#网络参数\n",
    "w1=tf.Variable(tf.truncated_normal([2,3],stddev=1,seed=1))\n",
    "w2=tf.Variable(tf.truncated_normal([3,1],stddev=1,seed=1))\n",
    "\n",
    "#前向传播\n",
    "a=tf.matmul(x,w1)\n",
    "y_hat=tf.matmul(a,w2)\n",
    "\n",
    "#损失函数\n",
    "loss = tf.reduce_mean(tf.square(y-y_hat))\n",
    "#反向传播\n",
    "train_step = tf.train.GradientDescentOptimizer(1e-3).minimize(loss)\n",
    "# train_step = tf.train.MomentumOptimizer(1e-3,1e-3).minimize(loss)\n",
    "# train_step = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "\n",
    "#会话\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    #训练前参数\n",
    "    print(\"before trian:\")\n",
    "    print(\"W1:\\n\",sess.run(w1))\n",
    "    print(\"W2:\\n\",sess.run(w2))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    #训练模型\n",
    "    EPOCHS = 1000\n",
    "    \n",
    "    for i in range(EPOCHS):\n",
    "        for j in range(int(32/BATCH_SIZE)):\n",
    "            start = j*BATCH_SIZE\n",
    "            end = start + BATCH_SIZE\n",
    "            sess.run(train_step,feed_dict={x:X[start:end],y:Y[start:end]})\n",
    "        if(i%100==0):\n",
    "            total_loss = sess.run(loss,feed_dict={x:X,y:Y})\n",
    "            print(\"after %d epochs,the loss is %g \"%(i,total_loss))\n",
    "    \n",
    "    \n",
    "    #训练后参数\n",
    "    print(\"after train:\")\n",
    "    print(\"W1:\\n\",sess.run(w1))\n",
    "    print(\"W2:\\n\",sess.run(w2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "after 0 iterations, train accuracy is 0.11 \n",
      "after 1000 iterations, train accuracy is 0.85 \n",
      "after 2000 iterations, train accuracy is 0.77 \n",
      "after 3000 iterations, train accuracy is 0.95 \n",
      "after 4000 iterations, train accuracy is 0.96 \n",
      "after 5000 iterations, train accuracy is 0.97 \n",
      "after 6000 iterations, train accuracy is 0.99 \n",
      "after 7000 iterations, train accuracy is 0.98 \n",
      "after 8000 iterations, train accuracy is 0.99 \n",
      "after 9000 iterations, train accuracy is 0.98 \n",
      "after 10000 iterations, train accuracy is 0.99 \n",
      "after 11000 iterations, train accuracy is 0.97 \n",
      "after 12000 iterations, train accuracy is 1 \n",
      "after 13000 iterations, train accuracy is 0.98 \n",
      "after 14000 iterations, train accuracy is 1 \n",
      "after 15000 iterations, train accuracy is 1 \n",
      "after 16000 iterations, train accuracy is 0.98 \n",
      "after 17000 iterations, train accuracy is 0.99 \n",
      "after 18000 iterations, train accuracy is 0.99 \n",
      "after 19000 iterations, train accuracy is 0.98 \n",
      "test accuracy is 0.965\n",
      "test accuracy is : 0.965\n",
      "前20张图片预测结果为：\n",
      "7,2,1,0,4,\t\n",
      "1,4,9,6,9,\t\n",
      "0,6,9,0,1,\t\n",
      "5,9,7,3,4,\t\n",
      "测试集前20张图片为：\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAD8CAYAAAC1p1UKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2Pqc46woWwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2571a6c2518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#手写数字识别【普通的神经网络】\n",
    "import tensorflow as tf \n",
    "import urllib \n",
    "from  tensorflow.examples.tutorials.mnist  import  input_data\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True) #MNIST数据输入\n",
    "\n",
    "#定义超参数\n",
    "input_size = 28*28\n",
    "hidden_size = 30\n",
    "output_size = 10\n",
    "batch_size = 100\n",
    "iteration = 20000\n",
    "\n",
    "#需要投喂的数据\n",
    "X = tf.placeholder(tf.float32,[None,input_size])\n",
    "Y = tf.placeholder(tf.float32,[None,output_size])\n",
    "\n",
    "#参数定义\n",
    "W1 = tf.Variable(tf.truncated_normal([input_size,hidden_size],stddev=0.1))\n",
    "B1 = tf.Variable(tf.constant(0.1),[hidden_size])\n",
    "W2 = tf.Variable(tf.truncated_normal([hidden_size,output_size],stddev=0.1))\n",
    "B2 = tf.Variable(tf.constant(0.1),[output_size])\n",
    "\n",
    "#网络结构定义\n",
    "hidden_value = tf.matmul(X,W1)+B1\n",
    "hidden_value = tf.nn.relu(hidden_value)\n",
    "output_value = tf.matmul(hidden_value,W2)+B2\n",
    "output_value = tf.nn.relu(output_value)\n",
    "\n",
    "\n",
    "#定义loss\n",
    "# loss = tf.reduce_mean(tf.square(output_value-Y))\n",
    "# loss = -tf.reduce_mean(Y*tf.log(a)+(1-Y)*tf.log(1-a),axis = 1)\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(labels=Y,logits=output_value)\n",
    "opt = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "# opt = tf.train.GradientDescentOptimizer(1e-3).minimize(loss)\n",
    "\n",
    "#定义准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(output_value,1),tf.argmax(Y,1)),\"float\"))\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #训练\n",
    "    for i in range(iteration):\n",
    "        batch_X , batch_Y = mnist.train.next_batch(batch_size)\n",
    "        _ , loss_value = sess.run([opt,loss],feed_dict={X:batch_X,Y:batch_Y})\n",
    "        if i%1000 == 0:\n",
    "            train_accuracy = sess.run(accuracy,feed_dict={X:batch_X,Y:batch_Y})\n",
    "            print(\"after %d iterations, train accuracy is %g \"%(i,train_accuracy))\n",
    "    #预测\n",
    "    test_accuracy = sess.run(accuracy,feed_dict={X:mnist.test.images,Y:mnist.test.labels})\n",
    "    print(\"test accuracy is %g\"%test_accuracy)\n",
    "    #可视化\n",
    "    n = 20 #显示前n张数字图片        \n",
    "    final_opt_a=tf.argmax (output_value, 1).eval(session=sess,feed_dict = {X: mnist.test.images,Y: mnist.test.labels})\n",
    "    y_ = sess.run(tf.argmax(mnist.test.labels,axis=1))\n",
    "    test_accuracy = tf.reduce_mean(tf.cast(tf.equal(y_,final_opt_a),\"float\"))\n",
    "    print(\"test accuracy is : %g\"%sess.run(test_accuracy))\n",
    "    fig, ax = plt.subplots(nrows=int(n/5),ncols=5 )\n",
    "    ax = ax.flatten()\n",
    "    print('前{}张图片预测结果为：'.format(n))\n",
    "    for i in range(n):\n",
    "        print(final_opt_a[i],end=',')\n",
    "        if int((i+1)%5) ==0:\n",
    "            print('\\t')\n",
    "        #图片可视化展示\n",
    "        img = mnist.test.images[i].reshape((28,28))#读取每行数据，格式为Ndarry\n",
    "        ax[i].imshow(img, cmap='Greys', interpolation='nearest')#可视化\n",
    "    print('测试集前{}张图片为：'.format(n))\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.33716384 -0.33716384]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[0.08979286,0.08979286,0.08979286,0.1325208,0.09812135,0.08979286,0.08979286,0.08979286,0.13547444,0.09512633],\n",
    "                 [0.08979286,0.08979286,0.08979286,0.1325208,0.09812135,0.08979286,0.08979286,0.08979286,0.13547444,0.09512633]])\n",
    "b = tf.constant([[0.,0. ,0., 0., 0., 0., 0., 1., 0., 0.],[0. ,0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.reduce_mean(b*tf.log(a)+(1-b)*tf.log(1-a),axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-1-89e9ea320dc3>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From E:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From E:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-1-89e9ea320dc3>:47: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "after 0 train accuracy:  0.1\n",
      "after 100 train accuracy:  0.14\n",
      "after 200 train accuracy:  0.1\n",
      "after 300 train accuracy:  0.08\n",
      "after 400 train accuracy:  0.04\n",
      "after 500 train accuracy:  0.14\n",
      "after 600 train accuracy:  0.12\n",
      "after 700 train accuracy:  0.18\n",
      "after 800 train accuracy:  0.16\n",
      "after 900 train accuracy:  0.14\n",
      "after 1000 train accuracy:  0.16\n",
      "after 1100 train accuracy:  0.18\n",
      "after 1200 train accuracy:  0.3\n",
      "after 1300 train accuracy:  0.4\n",
      "after 1400 train accuracy:  0.68\n",
      "after 1500 train accuracy:  0.94\n",
      "after 1600 train accuracy:  0.94\n",
      "after 1700 train accuracy:  0.94\n",
      "after 1800 train accuracy:  1.0\n",
      "after 1900 train accuracy:  0.88\n",
      "after 2000 train accuracy:  0.98\n",
      "after 2100 train accuracy:  0.98\n",
      "after 2200 train accuracy:  1.0\n",
      "after 2300 train accuracy:  0.98\n",
      "after 2400 train accuracy:  0.94\n",
      "after 2500 train accuracy:  0.94\n",
      "after 2600 train accuracy:  1.0\n",
      "after 2700 train accuracy:  0.96\n",
      "after 2800 train accuracy:  1.0\n",
      "after 2900 train accuracy:  0.98\n",
      "after 3000 train accuracy:  1.0\n",
      "after 3100 train accuracy:  0.98\n",
      "after 3200 train accuracy:  0.98\n",
      "after 3300 train accuracy:  1.0\n",
      "after 3400 train accuracy:  1.0\n",
      "after 3500 train accuracy:  0.98\n",
      "after 3600 train accuracy:  1.0\n",
      "after 3700 train accuracy:  0.98\n",
      "after 3800 train accuracy:  0.98\n",
      "after 3900 train accuracy:  1.0\n",
      "after 4000 train accuracy:  1.0\n",
      "after 4100 train accuracy:  0.96\n",
      "after 4200 train accuracy:  1.0\n",
      "after 4300 train accuracy:  0.98\n",
      "after 4400 train accuracy:  1.0\n",
      "after 4500 train accuracy:  1.0\n",
      "after 4600 train accuracy:  0.98\n",
      "after 4700 train accuracy:  1.0\n",
      "after 4800 train accuracy:  1.0\n",
      "after 4900 train accuracy:  1.0\n",
      "after 5000 train accuracy:  1.0\n",
      "after 5100 train accuracy:  1.0\n",
      "after 5200 train accuracy:  1.0\n",
      "after 5300 train accuracy:  1.0\n",
      "after 5400 train accuracy:  1.0\n",
      "after 5500 train accuracy:  1.0\n",
      "after 5600 train accuracy:  0.98\n",
      "after 5700 train accuracy:  0.98\n",
      "after 5800 train accuracy:  1.0\n",
      "after 5900 train accuracy:  1.0\n",
      "after 6000 train accuracy:  0.98\n",
      "after 6100 train accuracy:  0.98\n",
      "after 6200 train accuracy:  1.0\n",
      "after 6300 train accuracy:  1.0\n",
      "after 6400 train accuracy:  1.0\n",
      "after 6500 train accuracy:  1.0\n",
      "after 6600 train accuracy:  1.0\n",
      "after 6700 train accuracy:  1.0\n",
      "after 6800 train accuracy:  1.0\n",
      "after 6900 train accuracy:  0.98\n",
      "after 7000 train accuracy:  0.98\n",
      "after 7100 train accuracy:  1.0\n",
      "after 7200 train accuracy:  1.0\n",
      "after 7300 train accuracy:  1.0\n",
      "after 7400 train accuracy:  0.98\n",
      "after 7500 train accuracy:  0.98\n",
      "after 7600 train accuracy:  1.0\n",
      "after 7700 train accuracy:  1.0\n",
      "after 7800 train accuracy:  1.0\n",
      "after 7900 train accuracy:  0.98\n",
      "after 8000 train accuracy:  1.0\n",
      "after 8100 train accuracy:  1.0\n",
      "after 8200 train accuracy:  1.0\n",
      "after 8300 train accuracy:  1.0\n",
      "after 8400 train accuracy:  1.0\n",
      "after 8500 train accuracy:  0.98\n",
      "after 8600 train accuracy:  0.98\n",
      "after 8700 train accuracy:  1.0\n",
      "after 8800 train accuracy:  1.0\n",
      "after 8900 train accuracy:  0.98\n",
      "after 9000 train accuracy:  1.0\n",
      "after 9100 train accuracy:  1.0\n",
      "after 9200 train accuracy:  1.0\n",
      "after 9300 train accuracy:  1.0\n",
      "after 9400 train accuracy:  1.0\n",
      "after 9500 train accuracy:  1.0\n",
      "after 9600 train accuracy:  1.0\n",
      "after 9700 train accuracy:  1.0\n",
      "after 9800 train accuracy:  0.98\n",
      "after 9900 train accuracy:  1.0\n",
      "test accuracy is  0.9836\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import urllib \n",
    "from  tensorflow.examples.tutorials.mnist  import  input_data\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True) #MNIST数据输入\n",
    "\n",
    "input_size = 28*28\n",
    "output_size = 10\n",
    "batch_size = 50\n",
    "iteration = 10000\n",
    "\n",
    "X = tf.placeholder(tf.float32,[None,input_size])\n",
    "X_image = tf.reshape(X,[-1,28,28,1])\n",
    "Y = tf.placeholder(tf.float32,[None,output_size])\n",
    "W_conv1 = tf.Variable(tf.truncated_normal([5,5,1,32],stddev=0.1))\n",
    "B_conv1 = tf.Variable(tf.constant(0.1),[32])\n",
    "W_conv2 = tf.Variable(tf.truncated_normal([5,5,32,64],stddev=0.1))\n",
    "B_conv2 = tf.Variable(tf.constant(0.1),64)\n",
    "\n",
    "#第一层卷积池化\n",
    "h_conv1 = tf.nn.conv2d(input=X_image,filter=W_conv1,strides=[1,1,1,1],padding=\"SAME\")+B_conv1\n",
    "h_pool1 = tf.nn.max_pool(value=h_conv1,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "\n",
    "#第二层卷积池化\n",
    "h_conv2 = tf.nn.conv2d(h_pool1,W_conv2,[1,1,1,1],\"SAME\")+B_conv2\n",
    "h_pool2 = tf.nn.max_pool(h_conv2,[1,2,2,1],[1,2,2,1],padding = \"SAME\")\n",
    "\n",
    "#全连接层\n",
    "feature = tf.reshape(h_pool2,[-1,7*7*64])\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([7*7*64,1024],stddev=0.1))\n",
    "B_fc1 = tf.Variable(tf.constant(0.1),[1024])\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([1024,10],stddev=0.1))\n",
    "B_fc2 = tf.Variable(tf.constant(0.1),[10])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(feature,W_fc1)+B_fc1)\n",
    "#drop out \n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)\n",
    "\n",
    "output_value = tf.nn.relu(tf.matmul(h_fc1_drop,W_fc2)+B_fc2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#定义loss，优化器\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(labels=Y,logits=output_value)\n",
    "opt = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(output_value,1),tf.argmax(Y,1)),\"float\"))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(iteration):\n",
    "        input_batch , label_batch = mnist.train.next_batch(batch_size)\n",
    "        _,loss_value = sess.run([opt,loss],feed_dict={X:input_batch,Y:label_batch,keep_prob:0.5})\n",
    "        if i % 100 == 0 :\n",
    "            print(\"after %d train accuracy: \"%i,sess.run(accuracy,feed_dict={X:input_batch,Y:label_batch,keep_prob:1.0}))\n",
    "            \n",
    "    \n",
    "    #测试集准确率\n",
    "    test_accuracy = sess.run(accuracy,feed_dict={X:mnist.test.images,Y:mnist.test.labels,keep_prob:0.5})\n",
    "    print(\"test accuracy is \",test_accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
